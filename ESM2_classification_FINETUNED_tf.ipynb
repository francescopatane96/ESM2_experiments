{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescopatane96/ESM2_experiments/blob/main/ESM2_classification_FINETUNED_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets"
      ],
      "metadata": {
        "id": "1xI0zejXCEVf"
      },
      "id": "1xI0zejXCEVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load finetuned model from huggingface"
      ],
      "metadata": {
        "id": "MgbSaokoQYHC"
      },
      "id": "MgbSaokoQYHC"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFEsmForSequenceClassification\n",
        "\n",
        "model = TFEsmForSequenceClassification.from_pretrained(\"francescopatane/esm2m35finetunedcytmem\", output_attentions=True)"
      ],
      "metadata": {
        "id": "xTvoLKmdSWws",
        "outputId": "735c633d-ccca-41a9-ded1-15262521df2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xTvoLKmdSWws",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFEsmForSequenceClassification.\n",
            "\n",
            "All the layers of TFEsmForSequenceClassification were initialized from the model checkpoint at francescopatane/esm2m35finetunedcytmem.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFEsmForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d29b4ed",
      "metadata": {
        "id": "7d29b4ed"
      },
      "source": [
        "## Tokenizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02baaf7",
      "metadata": {
        "id": "c02baaf7"
      },
      "source": [
        "All inputs to neural nets must be numerical. The process of converting strings into numerical indices suitable for a neural net is called **tokenization**. For natural language this can be quite complex, as usually the network's vocabulary will not contain every possible word, which means the tokenizer must handle splitting rarer words into pieces, as well as all the complexities of capitalization and unicode characters and so on.\n",
        "\n",
        "With proteins, however, things are very easy. In protein language models, each amino acid is converted to a single token. Every model on `transformers` comes with an associated `tokenizer` that handles tokenization for it, and protein language models are no different. Let's get our tokenizer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ddbe2b2d",
      "metadata": {
        "id": "ddbe2b2d"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_for_tokenizer = \"francescopatane/esm2m35finetunedcytmem\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_for_tokenizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_predict = [\"MKGKNRSLFVLLVLLLLHKVNNVLLERTIETLLECKNEYVKGENGYKLAKGHHCVEEDNL\\\n",
        "ERWLQGTNERRSEENIKYKYGVTELKIKYAQMNGKRSSRILKESIYGAHNFGGNSYMEGK\\\n",
        "DGGDKTGEEKDGEHKTDSKTDNGKGANNLVMLDYETSSNGQPAGTLDNVLEFVTGHEGNS\\\n",
        "RKNSSNGGNPYDIDHKKTISSAIINHAFLQNTVMKNCNYKRKRRERDWDCNTKKDVCIPD\\\n",
        "RRYQLCMKELTNLVNNTDTNFHRDITFRKLYLKRKLIYDAAVEGDLLLKLNNYRYNKDFC\\\n",
        "KDIRWSLGDFGDIIMGTDMEGIGYSKVVENNLRSIFGTDEKAQQRRKQWWNESKAQIWTA\\\n",
        "MMYSVKKRLKGNFIWICKLNVAVNIEPQIYRWIREWGRDYVSELPTEVQKLKEKCDGKIN\\\n",
        "YTDKKVCKVPPCQNACKSYDQWITRKKNQWDVLSNKFISVKNAEKVQTAGIVTPYDILKQ\\\n",
        "ELDEFNEVAFENEINKRDGAYIELCVCSVEEAKKNTQEVVTNVDNAAKSQATNSNPISQP\\\n",
        "VDSSKAEKVPGDSTHGNVNSGQDSSTTGKAVTGDGQNGNQTPAESDVQRSDIAESVSAKN\\\n",
        "VDPQKSVSKRSDDTASVTGIAEAGKENLGASNSRPSESTVEANSPGDDTVNSASIPVVSG\\\n",
        "ENPLVTPYNGLRHSKDNSDSDGPAESMANPDSNSKGETGKGQDNDMAKATKDSSNSSDGT\\\n",
        "SSATGDTTDAVDREINKGVPEDRDKTVGSKDGGGEDNSANKDAATVVGEDRIRENSAGGS\\\n",
        "TNDRSKNDTEKNGASTPDSKQSEDATALSKTESLESTESGDRTTNDTTNSLENKNGGKEK\\\n",
        "DLQKHDFKSNDTPNEEPNSDQTTDAEGHDRDSIKNDKAERRKHMNKDTFTKNTNSHHLNS\\\n",
        "NNNLSNGKLDIKEYKYRDVKATREDIILMSSVRKCNNNISLEYCNSVEDKISSNTCSREK\\\n",
        "SKNLCCSISDFCLNYFDVYSYEYLSCMKKEFEDPSYKCFTKGGFKDKTYFAAAGALLILL\\\n",
        "LLIA\"]"
      ],
      "metadata": {
        "id": "9mY8jzabVg-7"
      },
      "id": "9mY8jzabVg-7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sequence = tokenizer(sequence_to_predict)"
      ],
      "metadata": {
        "id": "_QAiHIbaVwWo",
        "outputId": "570a409b-d64c-4790-d761-2a0c90fba078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_QAiHIbaVwWo",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the dataset"
      ],
      "metadata": {
        "id": "AG36GZPUbS2z"
      },
      "id": "AG36GZPUbS2z"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_dict(tokenized_sequence)"
      ],
      "metadata": {
        "id": "22LjBRjEWYtI"
      },
      "id": "22LjBRjEWYtI",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create tensors"
      ],
      "metadata": {
        "id": "tPLKdgmdbaBv"
      },
      "id": "tPLKdgmdbaBv"
    },
    {
      "cell_type": "code",
      "source": [
        "tf_set = model.prepare_tf_dataset(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "WWlK51yGW1ID"
      },
      "id": "WWlK51yGW1ID",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "qj7EeFb5bf_y"
      },
      "id": "qj7EeFb5bf_y"
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(tf_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hw14J5GWMPt",
        "outputId": "297592bc-7800-4445-f1ae-4d57f8822f71"
      },
      "id": "-Hw14J5GWMPt",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 15s 15s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's inspect the output of the transformer:\n"
      ],
      "metadata": {
        "id": "S5WVEDwClRdK"
      },
      "id": "S5WVEDwClRdK"
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "yDKibDaXlEyI"
      },
      "id": "yDKibDaXlEyI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- loss: None\n",
        "- logits: output values (not normalized) associated with the two possible labels (0 or 1). the higher logit value corresponds to relate label choosen by the model.\n",
        "- hidden states: None\n",
        "- attentions: a list of tensors that contains attention weights for every input token respect to every other input token. they can be used to find the relevance of input regions to determine the prediction."
      ],
      "metadata": {
        "id": "2Met00lNlYpm"
      },
      "id": "2Met00lNlYpm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save attentions from output"
      ],
      "metadata": {
        "id": "KX3CJKbdbiqB"
      },
      "id": "KX3CJKbdbiqB"
    },
    {
      "cell_type": "code",
      "source": [
        "attentions = pred.attentions"
      ],
      "metadata": {
        "id": "ViB4_15qY15C"
      },
      "id": "ViB4_15qY15C",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers interpret"
      ],
      "metadata": {
        "id": "dOeqOAztDng2"
      },
      "id": "dOeqOAztDng2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}